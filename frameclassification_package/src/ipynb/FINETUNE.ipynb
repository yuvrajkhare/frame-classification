{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01ouifzOX1_Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import timm\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "class SurgicalImagesDataset(Dataset):\n",
        "    def __init__(self, annotations_file, image_dir, augmented_image_dir=None, transform=None):\n",
        "        self.annotations = self.parse_annotations(annotations_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.augmented_image_dir = augmented_image_dir or \"augmented_images\"\n",
        "        self.transform = transform\n",
        "\n",
        "        # If augmented images directory is provided, assign class 2 to all images there\n",
        "        self.augmented_images = []\n",
        "        if augmented_image_dir:\n",
        "            for fname in os.listdir(augmented_image_dir):\n",
        "                if fname.endswith(('.jpg', '.png', '.jpeg')):  # Check for image files\n",
        "                    self.augmented_images.append({'name': fname, 'label': 2})\n",
        "\n",
        "    def parse_annotations(self, xml_file):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        images = []\n",
        "        labels = {}\n",
        "\n",
        "        for label_elem in root.findall('.//label'):\n",
        "            label_name = label_elem.find('name').text\n",
        "            labels[label_name] = len(labels)\n",
        "\n",
        "        for image_elem in root.findall('.//image'):\n",
        "            tag_elem = image_elem.find('tag')\n",
        "            if tag_elem is None:\n",
        "                continue\n",
        "\n",
        "            label_name = tag_elem.get('label')\n",
        "            if label_name not in labels:\n",
        "                continue\n",
        "\n",
        "            image_data = {\n",
        "                'name': image_elem.get('name'),\n",
        "                'label': labels[label_name]\n",
        "            }\n",
        "            images.append(image_data)\n",
        "        return images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations) + len(self.augmented_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < len(self.annotations):\n",
        "            image_data = self.annotations[idx]\n",
        "            image_name = image_data['name']\n",
        "            label = image_data['label']\n",
        "            image_path = os.path.join(self.image_dir, image_name)\n",
        "        else:\n",
        "            image_data = self.augmented_images[idx - len(self.annotations)]\n",
        "            image_name = image_data['name']\n",
        "            label = image_data['label']\n",
        "            image_path = os.path.join(self.augmented_image_dir, image_name)\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        # Apply transformations if any\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(F_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(F_loss)\n",
        "        else:\n",
        "            return F_loss\n",
        "\n",
        "class TransformSubset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.subset[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Paths to annotations and images\n",
        "annotations_files = ['/path_to_annotations1.xml',\n",
        "                     '/path_to_annotations2.xml',\n",
        "                     '/path_to_annotations3.xml']\n",
        "image_dirs = ['/path_to_labelled_dataset1/images',\n",
        "              '/path_to_labelled_dataset2/images',\n",
        "              '/path_to_labelled_dataset3/images']\n",
        "\n",
        "augmented_images_dir = '/path_to_augmented_frames_/highresolution_frames'\n",
        "\n",
        "# Load datasets without augmentation\n",
        "datasets = [SurgicalImagesDataset(ann_file, image_dir, augmented_image_dir=augmented_images_dir)\n",
        "            for ann_file, image_dir in zip(annotations_files, image_dirs)]\n",
        "\n",
        "combined_dataset = ConcatDataset(datasets)\n",
        "\n",
        "# Augmentation transforms for training\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Transforms for validation\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Extract targets for stratified splitting\n",
        "def extract_targets_from_concat_dataset(concat_dataset):\n",
        "    all_targets = []\n",
        "    for dataset in concat_dataset.datasets:\n",
        "        all_targets.extend([annotation['label'] for annotation in dataset.annotations])\n",
        "    return torch.tensor(all_targets)\n",
        "\n",
        "all_targets = extract_targets_from_concat_dataset(combined_dataset)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define SimCLRHead for classification, matching the pre-training architecture\n",
        "class SimCLRHead(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hidden_dim=2048):\n",
        "        super(SimCLRHead, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),  # Increase dimensionality to hidden_dim (e.g., 2048)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, out_dim),  # Reduce to the desired output dimension (e.g., 128)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mlp(x)\n",
        "        return F.normalize(x, dim=-1)\n",
        "\n",
        "    base_model = timm.create_model('tf_efficientnetv2_s', pretrained=True)\n",
        "    num_ftrs = base_model.classifier.in_features\n",
        "    base_model.classifier = nn.Identity()  # Remove the classifier layer\n",
        "\n",
        "    # Define the SimCLR model (base model + SimCLR head)\n",
        "    simclr_head = SimCLRHead(num_ftrs, 128, hidden_dim=2048)  # Match the hidden_dim used during pretraining\n",
        "    simclr_model = nn.Sequential(base_model, simclr_head)\n",
        "\n",
        "    # Load the pre-trained SimCLR weights\n",
        "    simclr_model.load_state_dict(torch.load('/path_to_load/pretrained_contrastive_weights_4.pth', map_location=torch.device('cpu')))\n",
        "    # Now that the weights are loaded, we can remove the SimCLR head and use the base model\n",
        "    base_model = simclr_model[0]  # Extract the base model without the SimCLR head\n",
        "\n",
        "    def create_classifier():\n",
        "        classifier = nn.Sequential(\n",
        "            base_model,          # Use the pre-trained EfficientNetV2-S model with loaded weights\n",
        "            nn.Flatten(),        # Flatten the output from the base model\n",
        "            nn.Linear(num_ftrs, 128),  # Add a fully connected layer\n",
        "            nn.ReLU(),           # Add ReLU activation for non-linearity\n",
        "            nn.Dropout(p=0.5),   # Add dropout with a 50% probability\n",
        "            nn.Linear(128, 3)    # Final layer for classification\n",
        "        )\n",
        "        return classifier\n",
        "\n",
        "# K-Fold Cross-Validation setup\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results_path = '/path_to_save_/saved_fold_metrics.pkl'\n",
        "\n",
        "# Initialize results storage\n",
        "fold_results = []\n",
        "fold_train_losses = []\n",
        "fold_val_losses = []\n",
        "fold_train_accuracies = []\n",
        "fold_val_accuracies = []\n",
        "fold_precisions = []\n",
        "fold_recalls = []\n",
        "fold_f1_scores = []\n",
        "fold_accuracies = []\n",
        "confusion_matrices = []\n",
        "all_fold_predictions = []\n",
        "all_fold_true_labels = []\n",
        "all_fold_probs = []\n",
        "\n",
        "# Paths for saving the best models and checkpoints\n",
        "checkpoint_dir = '/path_to_save_foldwise_/checkpoints_/'\n",
        "\n",
        "# Ensure checkpoint directory exists\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "# Track the current fold and model index\n",
        "current_fold = 0\n",
        "\n",
        "# Save/load fold and model index\n",
        "fold_model_state_path = 'path_to_save/fold_model_state.pkl'\n",
        "\n",
        "# Training loop with cross-validation\n",
        "num_epochs = 30\n",
        "patience = 3\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "def save_checkpoint(state, filename='checkpoint.pth'):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(filename):\n",
        "    checkpoint = torch.load(filename)\n",
        "    return checkpoint\n",
        "\n",
        "for fold, (train_val_idx, _) in enumerate(kf.split(torch.zeros(len(all_targets)), all_targets)):\n",
        "    # Split the train_val_idx further into train and validation indices\n",
        "    train_val_subset = Subset(combined_dataset, train_val_idx)\n",
        "\n",
        "    # Split train_val_subset into training and validation sets\n",
        "    train_size = int(0.8 * len(train_val_subset))\n",
        "    val_size = len(train_val_subset) - train_size\n",
        "\n",
        "    # Create Subsets\n",
        "    train_indices, val_indices = torch.utils.data.random_split(list(range(len(train_val_subset))), [train_size, val_size])\n",
        "\n",
        "    # Create Subsets\n",
        "    train_subset = Subset(train_val_subset, train_indices)\n",
        "    val_subset = Subset(train_val_subset, val_indices)\n",
        "\n",
        "    # Initialize the criterion with dynamic class weights\n",
        "    # Define the criterion with FocalLoss\n",
        "    criterion = FocalLoss(alpha=1, gamma=2)  # You can adjust alpha and gamma based on your needs\n",
        "\n",
        "\n",
        "    # Apply the transforms using TransformSubset\n",
        "    train_dataloader = DataLoader(TransformSubset(train_subset, transform=train_transforms), batch_size=128, shuffle=True, num_workers=2)\n",
        "    val_dataloader = DataLoader(TransformSubset(val_subset, transform=val_transforms), batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Instantiate the classifier model\n",
        "    classifier = create_classifier().to(device)\n",
        "\n",
        "    optimizer = optim.Adam(classifier.parameters(), lr=0.0001, weight_decay=1e-4)  # Adjust weight_decay\n",
        "    start_epoch = 0\n",
        "    best_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    # Initialize the learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        classifier.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        for batch_idx, (images, labels) in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():  # Mixed precision training\n",
        "                outputs = classifier(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Update progress bar with loss and accuracy\n",
        "            progress_bar.set_postfix(loss=loss.item(), accuracy=100 * correct / total)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_dataloader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_acc)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "        # Validation\n",
        "        classifier.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_dataloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = classifier(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_dataloader)\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        # Save the model with the best validation loss\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save(classifier.state_dict(), os.path.join(checkpoint_dir, f'/path_to_save_foldwise_/best_model_fold{fold+1}_val_loss.pth'))\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        # Save the model with the best validation accuracy\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(classifier.state_dict(), os.path.join(checkpoint_dir, f'/path_to_save_foldwise_/best_model_fold{fold+1}_val_acc.pth'))\n",
        "\n",
        "        # Save checkpoint\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': classifier.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'best_loss': best_loss,\n",
        "            'best_val_acc': best_val_acc,\n",
        "            'epochs_no_improve': epochs_no_improve,\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'train_accuracies': train_accuracies,\n",
        "            'val_accuracies': val_accuracies\n",
        "        }, filename=os.path.join(checkpoint_dir, f'checkpoint_fold{fold+1}.pth'))\n",
        "\n",
        "    # Evaluate on validation set (used as test here)\n",
        "    classifier.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "    all_val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = classifier(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_probs.extend(outputs.cpu().numpy())  # Save probabilities\n",
        "            all_val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Save predictions, probabilities, and true labels for this fold\n",
        "    all_fold_predictions.append(all_preds)\n",
        "    all_fold_true_labels.append(all_val_labels)\n",
        "    all_fold_probs.append(all_probs)\n",
        "\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    fold_accuracies.append(val_acc)\n",
        "\n",
        "    # Calculate precision, recall, f1-score for each class on validation set\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_val_labels, all_preds, average=None)\n",
        "    accuracy = accuracy_score(all_val_labels, all_preds)\n",
        "\n",
        "    fold_precisions.append(precision)\n",
        "    fold_recalls.append(recall)\n",
        "    fold_f1_scores.append(f1)\n",
        "\n",
        "    fold_results.append({'fold': fold + 1, 'val_loss': best_loss, 'val_acc': best_val_acc, 'test_acc': val_acc})\n",
        "    fold_train_losses.append(train_losses)\n",
        "    fold_val_losses.append(val_losses)\n",
        "    fold_train_accuracies.append(train_accuracies)\n",
        "    fold_val_accuracies.append(val_accuracies)\n",
        "\n",
        "    # Compute and store confusion matrix\n",
        "    cm = confusion_matrix(all_val_labels, all_preds)\n",
        "    confusion_matrices.append(cm)\n",
        "\n",
        "    # Save results after each fold\n",
        "    with open(results_path, 'wb') as f:\n",
        "        pickle.dump({\n",
        "            'fold_results': fold_results,\n",
        "            'fold_train_losses': fold_train_losses,\n",
        "            'fold_val_losses': fold_val_losses,\n",
        "            'fold_train_accuracies': fold_train_accuracies,\n",
        "            'fold_val_accuracies': fold_val_accuracies,\n",
        "            'fold_precisions': fold_precisions,\n",
        "            'fold_recalls': fold_recalls,\n",
        "            'fold_f1_scores': fold_f1_scores,\n",
        "            'fold_accuracies': fold_accuracies,\n",
        "            'confusion_matrices': confusion_matrices,\n",
        "            'all_fold_predictions': all_fold_predictions,\n",
        "            'all_fold_true_labels': all_fold_true_labels,\n",
        "            'all_fold_probs': all_fold_probs\n",
        "        }, f)\n",
        "\n",
        "    # Update the fold and model index state\n",
        "    with open(fold_model_state_path, 'wb') as f:\n",
        "        pickle.dump((fold + 1, 0), f)  # Move to the next fold\n",
        "\n",
        "# Save the fold-wise predictions, probabilities, and true labels using pickle\n",
        "with open('/path_to_save_foldwise_predictions.pkl', 'wb') as f:\n",
        "    pickle.dump(all_fold_predictions, f)\n",
        "with open('/path_to_save_foldwise_truelabels.pkl', 'wb') as f:\n",
        "    pickle.dump(all_fold_true_labels, f)\n",
        "with open('/path_to_save_foldwise_probablities', 'wb') as f:\n",
        "    pickle.dump(all_fold_probs, f)\n",
        "\n",
        "# Print the results fold-wise\n",
        "for i in range(len(fold_results)):\n",
        "    print(f\"Fold {fold_results[i]['fold']}:\")\n",
        "    print(f\"  Validation Loss: {fold_results[i]['val_loss']:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {fold_results[i]['val_acc']:.2f}%\")\n",
        "    print(f\"  Test Accuracy: {fold_results[i]['test_acc']:.2f}%\")\n",
        "    print(f\"  Precision (%):\")\n",
        "    for j in range(len(fold_precisions[i])):\n",
        "        print(f\"    Class {j}: {fold_precisions[i][j]*100:.2f}%\")\n",
        "    print(f\"  Recall (%):\")\n",
        "    for j in range(len(fold_recalls[i])):\n",
        "        print(f\"    Class {j}: {fold_recalls[i][j]*100:.2f}%\")\n",
        "    print(f\"  F1 Score:\")\n",
        "    for j in range(len(fold_f1_scores[i])):\n",
        "        print(f\"    Class {j}: {fold_f1_scores[i][j]:.2f}\")\n",
        "    print()  # Empty line for separation between folds\n",
        "\n",
        "# Plotting accuracy and loss curves for each fold\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "# Plot accuracy curves\n",
        "plt.subplot(2, 1, 1)\n",
        "for i, (train_accuracies, val_accuracies) in enumerate(zip(fold_train_accuracies, fold_val_accuracies)):\n",
        "    plt.plot(train_accuracies, label=f'Train Accuracy Fold {i+1}')\n",
        "    plt.plot(val_accuracies, label=f'Val Accuracy Fold {i+1}')\n",
        "plt.title('Accuracy Curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "# Plot loss curves\n",
        "plt.subplot(2, 1, 2)\n",
        "for i, (train_losses, val_losses) in enumerate(zip(fold_train_losses, fold_val_losses)):\n",
        "    plt.plot(train_losses, label=f'Train Loss Fold {i+1}')\n",
        "    plt.plot(val_losses, label=f'Val Loss Fold {i+1}')\n",
        "plt.title('Loss Curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrices\n",
        "for i, cm in enumerate(confusion_matrices):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix for Fold {i+1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n"
      ]
    }
  ]
}