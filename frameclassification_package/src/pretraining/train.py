# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QpVSBEuWzLL9-_R_X5ECemP7kmGVl6KN
"""

import torch
import torch.optim as optim
from torch.cuda.amp import GradScaler, autocast
from tqdm import tqdm
from pretraining.model import create_pretraining_model
from pretraining.dataset import UnannotatedImagesDataset
from pretraining.augmentations import TaskSpecificAugmentations,random_non_surgical_augmentation
from torch.utils.data import DataLoader
from torchvision.transforms import transforms
from utils.losses import reverse_triplet_loss
from utils.visualization import visualize_embeddings

def train_pretraining_model(image_dir, epochs=30, batch_size=64, checkpoint_path='/content/drive/MyDrive/checkpoint_pretraining_model.pth.tar'):
    print("Initializing training...", flush=True)

    # Define the device at the very beginning
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}", flush=True)

    # Initialize task-specific augmentations
    task_specific_augmentations = TaskSpecificAugmentations()

    # Define the transformations
    transform_blur = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.GaussianBlur(7),
        transforms.ToTensor(),
        transforms.Lambda(lambda img: torch.nn.functional.interpolate(img.unsqueeze(0), scale_factor=0.5, mode='bilinear', align_corners=False).squeeze(0)),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    transform_sharp = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    transform_non_surgical = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Lambda(lambda img: random_non_surgical_augmentation(img)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    print("Loading dataset...", flush=True)
    dataset = UnannotatedImagesDataset(
        image_dir=image_dir,
        transform_blur=transform_blur,
        transform_sharp=transform_sharp,
        transform_non_surgical=transform_non_surgical
    )
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)

    # Create the model and move it to the correct device
    model = create_pretraining_model().to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)
    scaler = GradScaler()

    patience = 3
    best_loss = float('inf')
    epochs_no_improve = 0

    print(f"Starting training for {epochs} epochs...", flush=True)

    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}", flush=True)
        model.train()
        epoch_loss = 0.0

        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f"Epoch [{epoch+1}/{epochs}]")
        for batch_idx, (blur_images, sharp_images, non_surgical_images) in progress_bar:
            blur_images = blur_images.to(device)
            sharp_images = sharp_images.to(device)
            non_surgical_images = non_surgical_images.to(device)

            optimizer.zero_grad()

            with autocast():
                blur_out = model(blur_images)
                sharp_out = model(sharp_images)
                non_surgical_out = model(non_surgical_images)
                loss = reverse_triplet_loss(blur_out, sharp_out, non_surgical_out, temperature=0.1)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += loss.item()
            progress_bar.set_postfix(loss=loss.item())

        avg_epoch_loss = epoch_loss / len(dataloader)
        print(f"Epoch [{epoch+1}/{epochs}] finished with Average Loss: {avg_epoch_loss:.4f}", flush=True)

        visualize_embeddings(model, dataloader, epoch + 1)

        if avg_epoch_loss < best_loss:
            best_loss = avg_epoch_loss
            epochs_no_improve = 0
            save_checkpoint({
                'epoch': epoch + 1,
                'state_dict': model.state_dict(),
                'best_loss': best_loss,
                'optimizer': optimizer.state_dict(),
            }, filename=checkpoint_path)
            print(f"New best model saved with Average Loss: {avg_epoch_loss:.4f}", flush=True)
        else:
            epochs_no_improve += 1
            print(f"No improvement in loss. {epochs_no_improve}/{patience} epochs without improvement.", flush=True)

        if epochs_no_improve >= patience:
            print("Early stopping triggered due to no improvement in loss.", flush=True)
            break

        if (epoch + 1) % 2 == 0:
            checkpoint_filename = f'/content/drive/MyDrive/checkpoint_pretraining_model_epoch_{epoch+1}.pth.tar'
            save_checkpoint({
                'epoch': epoch + 1,
                'state_dict': model.state_dict(),
                'best_loss': best_loss,
                'optimizer': optimizer.state_dict(),
            }, filename=checkpoint_filename)
            print(f"Checkpoint saved at {checkpoint_filename}", flush=True)

    final_model_path = '/content/drive/MyDrive/pretrained_model_pretraining.pth'
    torch.save(model.state_dict(), final_model_path)
    print(f"Training complete. Final model saved at {final_model_path}", flush=True)

def save_checkpoint(state, filename):
    torch.save(state, filename)
    print(f"Checkpoint saved to {filename}", flush=True)
