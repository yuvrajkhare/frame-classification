# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SRaS0u-ddU9ULvV96WZSop4zXNmk0_YL
"""

import os
from PIL import Image
from torch.utils.data import Dataset
from torchvision.transforms import transforms

class UnannotatedImagesDataset(Dataset):
    def __init__(self, image_dir, transform_blur=None, transform_sharp=None, transform_non_surgical=None):
        self.image_dir = image_dir
        self.transform_blur = transform_blur
        self.transform_sharp = transform_sharp
        self.transform_non_surgical = transform_non_surgical
        self.image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith(('jpg', 'jpeg', 'png'))]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')

        image_blur = self.transform_blur(image) if self.transform_blur else transforms.ToTensor()(image)
        image_sharp = self.transform_sharp(image) if self.transform_sharp else transforms.ToTensor()(image)
        image_non_surgical = self.transform_non_surgical(image) if self.transform_non_surgical else transforms.ToTensor()(image)

        image_blur = transforms.Resize((224,224))(image_blur)
        image_sharp = transforms.Resize((224,224))(image_sharp)
        image_non_surgical = transforms.Resize((224,224))(image_non_surgical)

        return image_blur, image_sharp, image_non_surgical