# -*- coding: utf-8 -*-
"""loss_functions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SRaS0u-ddU9ULvV96WZSop4zXNmk0_YL
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)
        pt = torch.exp(-BCE_loss)
        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss

        if self.reduction == 'mean':
            return torch.mean(F_loss)
        elif self.reduction == 'sum':
            return torch.sum(F_loss)
        else:
            return F_loss

def reverse_triplet_loss(blur_out, sharp_out, non_surgical_out, temperature=0.1):
    sim_blur_sharp = F.cosine_similarity(blur_out, sharp_out, dim=-1)
    sim_sharp_non_surgical = F.cosine_similarity(sharp_out, non_surgical_out, dim=-1)
    sim_blur_non_surgical = F.cosine_similarity(blur_out, non_surgical_out, dim=-1)

    reverse_loss_blur_sharp = -sim_blur_sharp.mean()
    reverse_loss_sharp_non_surgical = -sim_sharp_non_surgical.mean()
    reverse_loss_blur_non_surgical = -sim_blur_non_surgical.mean()

    total_reverse_loss = (reverse_loss_blur_sharp + reverse_loss_sharp_non_surgical + reverse_loss_blur_non_surgical) / 3.0

    return total_reverse_loss