{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dGWV2nCYNcM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import timm  # Import timm for model loading\n",
        "import random\n",
        "import string\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "import umap.umap_ as umap\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Task-Specific Augmentations for Non-Surgical Images\n",
        "class TaskSpecificAugmentations:\n",
        "    def __init__(self, watermark_text=None, watermark_size_range=(100, 100), random_text_length=8, font_path=None):\n",
        "        self.watermark_text = watermark_text\n",
        "        self.watermark_size_range = watermark_size_range\n",
        "        self.random_text_length = random_text_length\n",
        "        self.font_path = font_path or \"/usr/share/fonts/truetype/Roboto-Regular.ttf\"\n",
        "\n",
        "    def generate_random_text(self):\n",
        "        return ''.join(random.choices(string.ascii_uppercase + string.digits, k=self.random_text_length))\n",
        "\n",
        "    def add_watermark(self, image):\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        width, height = image.size\n",
        "        text = self.watermark_text if self.watermark_text else self.generate_random_text()\n",
        "\n",
        "        font_size = random.randint(*self.watermark_size_range)\n",
        "        font = ImageFont.truetype(self.font_path, font_size)  # Use the specified TrueType font\n",
        "        text_bbox = draw.textbbox((0, 0), text, font=font)\n",
        "        text_width = text_bbox[2] - text_bbox[0]\n",
        "        text_height = text_bbox[3] - text_bbox[1]\n",
        "        position = ((width - text_width) // 2, (height - text_height) // 2)\n",
        "\n",
        "        draw.text(position, text, fill=(255, 255, 255), font=font)\n",
        "        return image\n",
        "\n",
        "    def make_non_surgical(self, image):\n",
        "        return image.convert(\"L\").convert(\"RGB\")\n",
        "\n",
        "def random_non_surgical_augmentation(img):\n",
        "    if random.random() > 0.5:\n",
        "        return task_specific_augmentations.make_non_surgical(img)\n",
        "    else:\n",
        "        return task_specific_augmentations.add_watermark(img)\n",
        "\n",
        "# Dataset class for loading images and applying augmentations\n",
        "class UnannotatedImagesDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform_blur=None, transform_sharp=None, transform_non_surgical=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform_blur = transform_blur\n",
        "        self.transform_sharp = transform_sharp\n",
        "        self.transform_non_surgical = transform_non_surgical\n",
        "        self.image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith(('jpg', 'jpeg', 'png'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        # Apply the specific transformations for blurred and sharp images\n",
        "        image_blur = self.transform_blur(image) if self.transform_blur else transforms.ToTensor()(image)\n",
        "        image_sharp = self.transform_sharp(image) if self.transform_sharp else transforms.ToTensor()(image)\n",
        "        image_non_surgical = self.transform_non_surgical(image) if self.transform_non_surgical else transforms.ToTensor()(image)\n",
        "\n",
        "        image_blur = transforms.Resize((224,224))(image_blur)\n",
        "        image_sharp = transforms.Resize((224,224))(image_sharp)\n",
        "        image_non_surgical = transforms.Resize((224,224))(image_non_surgical)\n",
        "\n",
        "        return image_blur, image_sharp, image_non_surgical\n",
        "\n",
        "# File paths and transformations\n",
        "newimages_image_dir = '/path_to_unlabelled_frames'\n",
        "\n",
        "# Transformation for Blurry (Uninformative) Images\n",
        "transform_blur = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.GaussianBlur(7),  # Apply Gaussian blur\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda img: F.interpolate(img.unsqueeze(0), scale_factor=0.5, mode='bilinear', align_corners=False).squeeze(0)),  # Downsample and then upsample to simulate low resolution\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Transformation for Sharp (Informative) Images\n",
        "transform_sharp = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "task_specific_augmentations = TaskSpecificAugmentations()\n",
        "\n",
        "# Transformation for Non-Surgical Images with Random Grayscale or Watermark\n",
        "transform_non_surgical = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Lambda(lambda img: random_non_surgical_augmentation(img)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the large unannotated dataset with task-specific augmentations\n",
        "newimages_dataset = UnannotatedImagesDataset(\n",
        "    newimages_image_dir,\n",
        "    transform_blur=transform_blur,\n",
        "    transform_sharp=transform_sharp,\n",
        "    transform_non_surgical=transform_non_surgical\n",
        ")\n",
        "contrastive_dataloader = DataLoader(newimages_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "# SimCLR Projection Head\n",
        "class SimCLRHead(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hidden_dim=2048):\n",
        "        super(SimCLRHead, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),  # Increase dimensionality to hidden_dim (e.g., 2048)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, out_dim),  # Reduce to the desired output dimension (e.g., 128)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mlp(x)\n",
        "        return F.normalize(x, dim=-1)  # L2 normalization to ensure unit-length vectors\n",
        "\n",
        "# Using EfficientNetV2-S model\n",
        "base_model = timm.create_model('tf_efficientnetv2_s', pretrained=True)\n",
        "\n",
        "# Get the number of input features for the final fully connected layer\n",
        "num_ftrs = base_model.classifier.in_features\n",
        "\n",
        "# Replace the fully connected layer with an identity layer\n",
        "base_model.classifier = nn.Identity()\n",
        "\n",
        "# Combine the backbone with the SimCLR head\n",
        "model = nn.Sequential(\n",
        "    base_model,\n",
        "    SimCLRHead(num_ftrs, 128)  # 128 is the dimensionality of the projection space\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "def reverse_triplet_loss(blur_out, sharp_out, non_surgical_out, temperature=0.1):\n",
        "    # Calculate similarities between different augmentations of the same image\n",
        "    sim_blur_sharp = F.cosine_similarity(blur_out, sharp_out, dim=-1)\n",
        "    sim_sharp_non_surgical = F.cosine_similarity(sharp_out, non_surgical_out, dim=-1)\n",
        "    sim_blur_non_surgical = F.cosine_similarity(blur_out, non_surgical_out, dim=-1)\n",
        "\n",
        "    # We want to minimize these similarities (i.e., push them apart)\n",
        "    reverse_loss_blur_sharp = -sim_blur_sharp.mean()\n",
        "    reverse_loss_sharp_non_surgical = -sim_sharp_non_surgical.mean()\n",
        "    reverse_loss_blur_non_surgical = -sim_blur_non_surgical.mean()\n",
        "\n",
        "    # Combine the reversed losses into a total loss\n",
        "    total_reverse_loss = (reverse_loss_blur_sharp + reverse_loss_sharp_non_surgical + reverse_loss_blur_non_surgical) / 3.0\n",
        "\n",
        "    return total_reverse_loss\n",
        "\n",
        "# Function to save checkpoints\n",
        "def save_checkpoint(state, filename='/path_to_checkpoint_contrastive.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_embeddings(model, dataloader, epoch):\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (blur_images, sharp_images, non_surgical_images) in dataloader:\n",
        "            blur_images = blur_images.to(device)\n",
        "            sharp_images = sharp_images.to(device)\n",
        "            non_surgical_images = non_surgical_images.to(device)\n",
        "\n",
        "            blur_out = model(blur_images).cpu().numpy()\n",
        "            sharp_out = model(sharp_images).cpu().numpy()\n",
        "            non_surgical_out = model(non_surgical_images).cpu().numpy()\n",
        "\n",
        "            embeddings.append(blur_out)\n",
        "            embeddings.append(sharp_out)\n",
        "            embeddings.append(non_surgical_out)\n",
        "\n",
        "            labels.extend([0] * blur_out.shape[0])\n",
        "            labels.extend([1] * sharp_out.shape[0])\n",
        "            labels.extend([2] * non_surgical_out.shape[0])\n",
        "\n",
        "    embeddings = np.concatenate(embeddings, axis=0)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    palette = sns.color_palette(\"Set2\", 3)  # Set2 is a palette with soft, yet distinct colors\n",
        "\n",
        "    # t-SNE\n",
        "    tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
        "    embeddings_tsne = tsne.fit_transform(embeddings)\n",
        "\n",
        "    # PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    embeddings_pca = pca.fit_transform(embeddings)\n",
        "\n",
        "    # UMAP\n",
        "    reducer = umap.UMAP()\n",
        "    embeddings_umap = reducer.fit_transform(embeddings)\n",
        "\n",
        "    plt.figure(figsize=(20, 6))\n",
        "\n",
        "    # t-SNE Plot\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.scatter(embeddings_tsne[labels == 0, 0], embeddings_tsne[labels == 0, 1], color=palette[0], label='Blurred', alpha=0.7, edgecolor='k')\n",
        "    plt.scatter(embeddings_tsne[labels == 1, 0], embeddings_tsne[labels == 1, 1], color=palette[1], label='Sharp', alpha=0.7, edgecolor='k')\n",
        "    plt.scatter(embeddings_tsne[labels == 2, 0], embeddings_tsne[labels == 2, 1], color=palette[2], label='Non-Surgical', alpha=0.7, edgecolor='k')\n",
        "    plt.legend()\n",
        "    plt.title(f't-SNE (Epoch {epoch})')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # PCA Plot\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.scatter(embeddings_pca[labels == 0, 0], embeddings_pca[labels == 0, 1], color=palette[0], label='Blurred', alpha=0.7, edgecolor='k')\n",
        "    plt.scatter(embeddings_pca[labels == 1, 0], embeddings_pca[labels == 1, 1], color=palette[1], label='Sharp', alpha=0.7, edgecolor='k')\n",
        "    plt.scatter(embeddings_pca[labels == 2, 0], embeddings_pca[labels == 2, 1], color=palette[2], label='Non-Surgical', alpha=0.7, edgecolor='k')\n",
        "    plt.legend()\n",
        "    plt.title(f'PCA (Epoch {epoch})')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # UMAP Plot\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.scatter(embeddings_umap[labels == 0, 0], embeddings_umap[labels == 0, 1], color=palette[0], label='Blurred', alpha=0.7, edgecolor='k')\n",
        "    plt.scatter(embeddings_umap[labels == 1, 0], embeddings_umap[labels == 1, 1], color=palette[1], label='Sharp', alpha=0.7, edgecolor='k')\n",
        "    plt.scatter(embeddings_umap[labels == 2, 0], embeddings_umap[labels == 2, 1], color=palette[2], label='Non-Surgical', alpha=0.7, edgecolor='k')\n",
        "    plt.legend()\n",
        "    plt.title(f'UMAP (Epoch {epoch})')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Training setup\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "scaler = GradScaler()  # Initialize the gradient scaler for mixed precision\n",
        "\n",
        "# Early stopping setup\n",
        "patience = 3\n",
        "best_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(30):  # Number of epochs\n",
        "    model.train()\n",
        "    epoch_loss = 0.0  # Initialize epoch loss\n",
        "\n",
        "    progress_bar = tqdm(enumerate(contrastive_dataloader), total=len(contrastive_dataloader), desc=f\"Epoch [{epoch+1}/30]\")\n",
        "    for batch_idx, (blur_images, sharp_images, non_surgical_images) in progress_bar:\n",
        "        blur_images = blur_images.to(device)\n",
        "        sharp_images = sharp_images.to(device)\n",
        "        non_surgical_images = non_surgical_images.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients at the start of each batch\n",
        "\n",
        "        with autocast():  # Enable mixed precision training\n",
        "            blur_out = model(blur_images)\n",
        "            sharp_out = model(sharp_images)\n",
        "            non_surgical_out = model(non_surgical_images)\n",
        "\n",
        "            # Use the contrastive loss\n",
        "            loss = reverse_triplet_loss(blur_out, sharp_out, non_surgical_out, temperature=0.1)\n",
        "\n",
        "        scaler.scale(loss).backward()  # Scale the loss and perform backpropagation\n",
        "\n",
        "        scaler.step(optimizer)  # Update model parameters\n",
        "        scaler.update()  # Update the scaler\n",
        "\n",
        "        epoch_loss += loss.item()  # Accumulate batch loss\n",
        "\n",
        "        # Update progress bar with loss\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(contrastive_dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/30], Average Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "    # Visualization after each epoch\n",
        "    visualize_embeddings(model, contrastive_dataloader, epoch + 1)\n",
        "\n",
        "    # Early stopping and best model checkpointing\n",
        "    if avg_epoch_loss < best_loss:\n",
        "        best_loss = avg_epoch_loss\n",
        "        epochs_no_improve = 0\n",
        "\n",
        "        # Save the best model checkpoint\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_loss': best_loss,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }, filename='/path_to_best_model_checkpoint.pth.tar')\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    if epochs_no_improve >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "    # Save regular checkpoints every few epochs\n",
        "    if (epoch + 1) % 2 == 0:  # For example, save every 2 epochs\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_loss': best_loss,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }, filename=f'/path_to_checkpoint_epoch_{epoch+1}.pth.tar')\n",
        "\n",
        "# Save the final model\n",
        "torch.save(model.state_dict(), '/path_to_pretrained_model_contrastive.pth')\n"
      ]
    }
  ]
}